
# Dynamic AI: Fractal Universe Chocolate Wafer Model (FUCWM)

### Watch Demo

Check out the demo of the project on YouTube: [Watch Here](https://www.youtube.com/live/d__ras4nLU4)

While you're at it, head over to Hugging Face and grab yourself a model:

**[Hugging Face Repository: DaFuc](https://huggingface.co/spaces/Aluode/DaFuc/tree/main)**

There are two versions of "Blue" (blue and blue3). Place them in the folder where the app is located and load them using the state save/load feature. Blue likes to talk about the color blue a lot. I started calling it Blue because it often speaks in wave-like terms. Perhaps it was talking about fractals with LM Studio, and then I joined in:

**[Watch the YouTube Video](https://www.youtube.com/live/d__ras4nLU4)**

It might be that I'm seeing something that isn't there, but there's something organic about it. For some reason, when I began talking Finnish, it didn't stick to its vocabulary.

---

## What is it?

Dynamic AI is an experimental neural network model inspired by fractal structures in the universe and the human brain. It incorporates recursive nodes (FractalNodes) to dynamically grow and learn through Hebbian-like updates and pruning. The model also integrates a VAE (Variational Autoencoder) for encoding latent space representations. This repository contains the code for training, chatting, and interacting with the model via a Gradio interface.

---

## Attention Mechanism (New)

The attention mechanism dynamically adjusts the focus of the model by assigning importance to different child nodes in the fractal structure. Each child node receives an attention score based on its relevance, calculated using a softmax function. This allows the model to prioritize certain nodes during the forward pass, enabling more efficient learning and processing. The model also maintains a co-activation matrix that tracks how frequently different nodes activate together, further refining the attention scores.

---

## Features

- **Recursive Fractal Nodes**: Nodes grow and create child nodes based on complexity, simulating the recursive, fractal-like nature of the brain and the universe.
- **Variational Autoencoder (VAE)**: Encodes latent representations of inputs.
- **Layer Normalization & Xavier Initialization**: Enhances training stability.
- **Dynamic Complexity-based Growth**: Nodes grow based on complexity thresholds and manage child connections.
- **Dynamic AI Chat**: Users can interact with the model to generate responses.
- **LM Studio Integration**: Chat with a local LM Studio instance in a collaborative conversational framework.
- **Gradio Interface**: A user-friendly interface to interact with the AI model, train it on Q&A pairs, and simulate conversations with LM Studio.

---

## Technical Details

Think of a fractal ball around the Big Bang, with chocolate wafer-inspired superweights that add complexity to normal weights. Now with an added attention mechanism, I asked Claude to think of node 1 as a sort of phone book that keeps tabs on child nodes and "hooks them up" if they fire together. So, they can wire together. You know what I mean.

The depth setting can cause the ball complexities to explode to NaN (out of range) territory very fast. There was a real fight to keep the complexity setting manageable.

---

## Requirements

- Python 3.8+
- PyTorch
- Gradio
- LM Studio (optional, for integration with the `talk_with_lm_studio` feature)

> **Note**: The `requirements.txt` was generated by ChatGPT, and I have not tested if it works as-is.

---

## Installation

1. Clone this repository:

   ```bash
   git clone https://github.com/anttiluode/DaFUC.git
   cd dynamic-ai-fractal-wafer
   ```

2. Install dependencies:

   ```bash
   pip install -r requirements.txt
   ```

3. If you're planning to use LM Studio, ensure it's installed and running locally. Configure the `lm_studio_client` by setting your API key and URL in the code.

4. Run the application:

   ```bash
   python app.py
   ```

---

## Usage

### 1. Chat with Dynamic AI

You can use the Gradio interface to chat with the Dynamic AI model.

- **Message**: Enter your message and adjust the temperature for creativity.
- **Response**: The AI will generate a response based on its knowledge.

### 2. Train the Model on Q&A Pairs

You can train the model using a JSON file containing question-answer pairs through the Gradio interface.

- **Q&A Pairs File**: Upload a JSON file with question-answer pairs.
- **Epochs**: Set the number of training epochs.
- **Training Output**: Monitor the training progress, including loss metrics.

> **Note**: This can cause the model to parrot the words in the Q&A pairs if the complexity isn't managed properly.

### 3. LM Studio Conversation

You may have to wait for the conversation to start. There could be multiple empty interactions, but eventually, the model will say something, and LM Studio will respond. If you train the model with Q&A pairs, the complexity may not stabilize.

On the initial live training video (linked at the top), something amazing happened: the complexity stabilized at 16 and didn’t budge.

- **Initial Message**: Set the initial message to start the conversation.
- **Duration**: Set the conversation's duration.
- **Delay**: Set the delay between messages.

### 4. Save/Load Model State

You can save and load the state of the model using the Gradio interface.

- **Save State**: Save the current model state to a file.
- **Load State**: Load a previously saved state to restore the model.

---

## Example

To chat with Dynamic AI using the command line interface:

```bash
python app.py
```

Then, access the Gradio interface from your browser. You can interact with the AI by typing messages, training it, or saving/loading its state.

---

## Training Data Format

The Q&A pairs should be in a JSON file in the following format:

```json
[
    {"question": "What is the capital of France?", "answer": "Paris"},
    {"question": "Who wrote '1984'?", "answer": "George Orwell"}
]
```

---

## Contribution

Feel free to contribute to this project by submitting pull requests or opening issues for improvements or bugs.

---

## Issues

The depth settings are critical:

```python
dynamic_ai = DynamicAI(vocab_size=50000, embed_dim=256, latent_dim=256, output_dim=256, max_depth=7)
```

The deeper the model gets, the more complex the "fractal ball" around the initial point (think Big Bang) becomes. If it gets too complex, you’ll hit NaN (out of reach) territory, and the model won’t work properly.

---

## License

This project is licensed under the MIT License.
